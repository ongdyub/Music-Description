{"cells":[{"cell_type":"markdown","metadata":{"id":"SG-6bXEdYY7D"},"source":["# **Colab Setting**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11221,"status":"ok","timestamp":1708246034586,"user":{"displayName":"Dongyub Han","userId":"17440959295923893762"},"user_tz":-540},"id":"e-1pRsW4BUYL","outputId":"ced081a5-4493-4abd-daa8-588ce0c08feb"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","wav_path = '/content/drive/MyDrive/LoLThemeAI'\n","save_path = '/content/drive/MyDrive/MusicDescription'\n","\n","import torch\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(device)\n","\n","import pandas as pd\n","df = pd.read_csv (save_path + '/data/caption_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4763,"status":"ok","timestamp":1708246039344,"user":{"displayName":"Dongyub Han","userId":"17440959295923893762"},"user_tz":-540},"id":"Dyy36IKY0Epi","outputId":"2d300435-8784-460a-e26c-518926f5e593"},"outputs":[],"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"]},{"cell_type":"markdown","metadata":{"id":"D9s95OhlsjqM"},"source":["# **Define Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zSnkIpQy7Lq"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from transformers import ASTConfig, ASTModel\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return x + self.pe[:x.size(0), :]\n","\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers):\n","        super(TransformerEncoder, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.pos_encoder = PositionalEncoding(d_model)\n","        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True), num_layers=num_encoder_layers)\n","\n","    def forward(self, src):\n","        src = self.embedding(src)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src)\n","        return output\n","\n","class ASTEncoder(nn.Module):\n","    def __init__(self):\n","        super(ASTEncoder, self).__init__()\n","        self.configuration = ASTConfig()\n","        self.encoder = ASTModel(self.configuration)\n","\n","    def forward(self, input_values):\n","        output = self.encoder(input_values)\n","        return output.last_hidden_state\n","\n","class TransformerDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, nhead, num_decoder_layers):\n","        super(TransformerDecoder, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.pos_encoder = PositionalEncoding(d_model)\n","        self.transformer_decoder = nn.TransformerDecoder(nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, batch_first=True), num_layers=num_decoder_layers)\n","        self.fc = nn.Linear(d_model, vocab_size)\n","\n","    def forward(self, tgt, memory, mask):\n","        tgt = self.embedding(tgt)\n","        tgt = self.pos_encoder(tgt)\n","        output = self.transformer_decoder(tgt, memory, tgt_mask=mask)\n","        output = self.fc(output)\n","        return output\n","\n","class Transformer(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Transformer, self).__init__()\n","        self.encoder = encoder\n","        # self.audio_encoder = encoder\n","        self.decoder = decoder\n","\n","    def generate_square_subsequent_mask(self, bsz, tgt_len):\n","        mask = (torch.triu(torch.ones(tgt_len, tgt_len)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask.unsqueeze(0).expand(bsz * 8, -1, -1).to(device)\n","\n","    def forward(self, src, tgt):\n","        bsz, len = tgt.shape\n","        tgt_mask = self.generate_square_subsequent_mask(bsz, len)\n","\n","        memory = self.encoder(src)\n","        # memory = self.audio_encoder(src)\n","        output = self.decoder(tgt, memory, tgt_mask)\n","        return output\n","\n","encoder = TransformerEncoder(vocab_size=2050, d_model=512, nhead=8, num_encoder_layers=6)\n","# audio_encoder = ASTEncoder()\n","decoder = TransformerDecoder(vocab_size=tokenizer.vocab_size, d_model=512, nhead=8, num_decoder_layers=6)\n","\n","# Define model\n","model = Transformer(encoder, decoder)"]},{"cell_type":"markdown","metadata":{"id":"NQmVmTEoslwi"},"source":["# **Set Hyperparams**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rW0nsEf51xIo"},"outputs":[],"source":["batch_size = 14\n","num_epochs = 500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8sITzd1y8_j"},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","\n","epsilon = 1e-9\n","# Use your custom optimizer & scheduler\n","# In my case, ~80 epoch use lr scheduler witch describe in original paper \"Attention is all you need\".\n","# Then, use cos scheduler in below code\n","\n","# optimizer = optim.AdamW(model.parameters(), lr=2e-5, eps=1e-9)\n","# scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-7)\n","\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"NqtK4eY864og"},"source":["# **Dataset Processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKo6zI0tBYNp"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoProcessor, EncodecModel, AutoFeatureExtractor\n","import librosa\n","\n","# Define your custom dataset\n","class MusicDescriptionDataset(Dataset):\n","    def __init__(self, data):\n","        super().__init__()\n","        self.data = data\n","\n","        self.audio_model = EncodecModel.from_pretrained(\"facebook/encodec_32khz\").to(device)\n","        self.audio_processor = AutoProcessor.from_pretrained(\"facebook/encodec_32khz\")\n","        # self.processor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n","        self.sos = 2048\n","        self.eos = 0\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        ytid = row['ytid']\n","        caption = str(row['caption'])\n","\n","        path_prefix = wav_path + '/data/wav/'\n","        output = self.tokenizer(caption, truncation=True, padding=\"max_length\", max_length=512, return_tensors='pt')\n","        labels = output['input_ids'].squeeze(0)\n","        labels = torch.cat((torch.tensor([self.sos]), labels[:-2], torch.tensor([0])), dim=0)\n","        labels = labels.to(device)\n","\n","        # encoded_input = tokenizer(caption, padding='max_length', max_length=200, return_tensors='pt')\n","        wav, or_sr = librosa.load(path_prefix + ytid + '.wav', sr=None)\n","\n","        audio = librosa.resample(wav, orig_sr=or_sr, target_sr=32000)\n","        audio_inputs = self.audio_processor(raw_audio=audio, sampling_rate=32000, return_tensors=\"pt\").to(device)\n","        audio_encoder_outputs = self.audio_model(**audio_inputs)\n","        audio_codes = audio_encoder_outputs.audio_codes\n","        frames, bsz, codebooks, seq_len = audio_codes.shape\n","\n","        decoder_input_ids = audio_codes[0, ...].reshape(bsz * 4, seq_len)\n","        input_ids = decoder_input_ids.t().contiguous().view(-1)\n","        input_ids = torch.cat((torch.tensor([self.sos]).to(device),input_ids, torch.tensor([self.eos]).to(device)), dim=0)\n","        input_ids = input_ids.to(device)\n","\n","        # wav = librosa.resample(wav, orig_sr=or_sr, target_sr=16000)\n","        # input_values = self.processor(wav, sampling_rate=16000, return_tensors=\"pt\")['input_values']\n","\n","        # input_values = input_values.squeeze(0).to(device)\n","\n","        return input_ids, labels\n","        # return input_values, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPl87z3vUE88"},"outputs":[],"source":["model_path = save_path + f\"/fast/epoch_{12}.pt\"\n","model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5408,"status":"ok","timestamp":1708246188768,"user":{"displayName":"Dongyub Han","userId":"17440959295923893762"},"user_tz":-540},"id":"TNMgTBm0REev","outputId":"9209d196-4281-4fcb-8a30-8e8cf400b364"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(df, test_size=0.1, random_state=11)\n","\n","train_dataset = MusicDescriptionDataset(train)\n","test_dataset = MusicDescriptionDataset(test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"fNbzQhAU9Gln"},"source":["# **Train & Eval**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tw7tqzaY_mpD"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def train(model, dataloader, optimizer, epoch):\n","    model.train()\n","    total_loss = 0\n","    for i, batch in enumerate(tqdm(dataloader)):\n","        input_ids, labels = batch\n","        # input_values, labels = batch\n","        optimizer.zero_grad()\n","\n","        outputs = model(input_ids, labels[:, :-1])\n","        outputs = outputs.view(-1, outputs.size(2))\n","        targets = labels[:, 1:].contiguous().view(-1)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    return total_loss / len(dataloader)\n","\n","def evaluate(model, dataloader):\n","    model.eval()\n","    total_loss = 0\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader):\n","            input_ids, labels = batch\n","            # input_values, labels = batch\n","\n","            outputs = model(input_ids, labels[:, :-1])\n","            # outputs = model(input_values, labels[:, :-1], train=False)\n","            outputs = outputs.view(-1, outputs.size(2))\n","            targets = labels[:, 1:].contiguous().view(-1)\n","            loss = criterion(outputs, targets)\n","\n","            total_loss += loss.item()\n","\n","    return total_loss / len(dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qihZcADVwcn5","outputId":"50a7682b-7738-4352-ebcd-d5f6463403af"},"outputs":[],"source":["for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, optimizer, epoch)\n","    test_loss = evaluate(model, test_loader)\n","\n","    scheduler.step()\n","    torch.save(model.state_dict(), save_path + f\"/model/epoch_{epoch+1}.pt\")\n","\n","    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:.8f}, Test Loss: {test_loss:.8f} LR: {scheduler.get_last_lr()[0]:.10f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP2D0OKf3Mof440zjevU1Qi","gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
